{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f530f21-e717-4b51-8ed0-10bfd5acdf95",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aacc21e-b962-4828-8be5-8c12fad9c164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain_community langchain_core langchain_openai langchain_mongodb pymongo pypdf PyPDFLoader create_metadata_tagger"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8958bd33-c372-4127-aacb-196c07f2aedf",
   "metadata": {},
   "source": [
    "# Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "92d776da-8ee1-47c1-9f0d-cf2b2bab7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Create config.ini\n",
    "\n",
    "# [OpenAI]\n",
    "# api_key = TBC\n",
    "\n",
    "# [MongoDB]\n",
    "# uri = TBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "d0de85b3-652f-4157-af76-08f77b438c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from configparser import ConfigParser\n",
    "config = ConfigParser()\n",
    "config.read('config.ini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "187eb643-11ba-4228-82aa-1bf6498781fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_openai_key = config['OpenAI']['api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fa2b23a1-bd41-4d45-9f59-d660ccd7cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb_uri = config['MongoDB']['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "baacd425-1d4c-4088-bae3-905ca136067b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_name = \"langchain_demo\"\n",
    "collection_name = \"chunked_data\"\n",
    "index = \"vector_index\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a715c6-1263-43ef-97fd-ae7424ff95d1",
   "metadata": {},
   "source": [
    "# Preparing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0387bb3a-e2fb-46b0-a437-e76416af4f72",
   "metadata": {},
   "source": [
    "#### Load a PDF file using LangChain and split it into multiple pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e3db87d5-fbb4-46ee-ba07-16f650e0de26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='' metadata={'source': './mongodb.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# TODO import the PyPDFLoader class from langchain_community.document_loaders\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "# TODO: Create an instance of the PyPDFLoader class with the path to the mongodb.pdf file\n",
    "loader = PyPDFLoader('./mongodb.pdf')\n",
    "\n",
    "# TODO: Load the pages of the PDF file\n",
    "pages = loader.load()\n",
    "\n",
    "# TODO: Print the first page of the PDF file\n",
    "print(pages[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19518c0-eb5d-43b3-b9f0-d6c5381c68ef",
   "metadata": {},
   "source": [
    "#### Clean and chunk data pulled from a PDF using a recursive text splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c45d4b25-e349-4ae3-aa88-437434280fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='familiar (or a schema for you Oracle folks). Within a MongoDB instance you can\n",
      "have zero or more databases, each acting as high-level containers for everything\n",
      "else.\n",
      "2.A database can have zero or more collections . A collection shares enough in\n",
      "common with a traditional table that you can safely think of the two as the same\n",
      "thing.\n",
      "3.Collections are made up of zero or more documents . Again, a document can safely\n",
      "be thought of as analogous to a row.' metadata={'source': './mongodb.pdf', 'page': 5}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import the RecursiveCharacterTextSplitter from the langchain.text_splitter module\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# TODO: Create an empty list called cleaned_pages\n",
    "cleaned_pages = []\n",
    "\n",
    "# TODO: Loop through the pages and only append the pages with more than 20 words to the cleaned_pages list\n",
    "for page in pages:\n",
    "    if len(page.page_content.split(\" \")) > 20:\n",
    "        cleaned_pages.append(page)\n",
    "        \n",
    "# TODO: Create a variable called text_splitter and set it to an instance of RecursiveCharacterTextSplitter \n",
    "# with a chunk_size set to 500 and the chunk_overlap set to 150\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500,\n",
    "  chunk_overlap=150)\n",
    "\n",
    "# TODO: Call the split_documents method on the text_splitter object and pass in the cleaned_pages list\n",
    "split_docs = text_splitter.split_documents(cleaned_pages)\n",
    "\n",
    "# Print the 21st element in the split_docs list\n",
    "print(split_docs[21])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb1aacb-6668-4e1d-94e0-eae9322d16ec",
   "metadata": {},
   "source": [
    "#### Create metadata for the chunks of data extracted from a PDF using LangChain and a large language model (LLM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7c43725-0554-4304-a023-7bc4d177c715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='About This Book\n",
      "License\n",
      "The Little MongoDB Book is licensed under the Attribution-NonCommercial 3.0 Unported\n",
      "license. Y ou should not have paid for this book.\n",
      "You are basically free to copy, distribute, modify or display the book. However, please\n",
      "always attribute the book to its original author - Karl Seguin - and do not use it for com-\n",
      "mercial purposes. You can see the full text of the license at: http://creativecommons.\n",
      "org/licenses/by-nc/3.0/legalcode\n",
      "About The Original Author' metadata={'title': 'The Little MongoDB Book', 'keywords': ['license', 'author', 'company', 'latest version'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 1}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Import create_metadata_tagger from langchain_community.document_transformers.openai_functions\n",
    "from langchain_community.document_transformers.openai_functions import create_metadata_tagger\n",
    "\n",
    "# TODO: Import ChatOpenAI from langchain_openai\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# TODO: Define schema for metadata tagging\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"title\": {\"type\": \"string\"},\n",
    "        \"keywords\": {\"type\": \"array\", \"items\": {\"type\": \"string\"}},\n",
    "        \"hasCode\": {\"type\": \"boolean\"},\n",
    "    },\n",
    "    \"required\": [\"title\", \"keywords\", \"hasCode\"],\n",
    "}\n",
    "\n",
    "# TODO: Create an instance of ChatOpenAI, called `llm`, using the mock_openai_key, a temperature of 0, and the model \"gpt-4o-mini\"\n",
    "llm = ChatOpenAI(openai_api_key=my_openai_key, temperature=0,\n",
    "    model=\"gpt-4o-mini\")\n",
    "\n",
    "# TODO: Create a document transformer using the create_metadata_tagger function, passing in the schema and llm\n",
    "document_transformer = create_metadata_tagger(schema, llm)\n",
    "\n",
    "# TODO: Create a `docs` variable by calling the transform_documents method on the document_transformer, passing in cleaned_pages\n",
    "docs = document_transformer.transform_documents(cleaned_pages)\n",
    "\n",
    "# TODO: Replace cleaned_pages with docs\n",
    "split_docs = text_splitter.split_documents(docs)\n",
    "\n",
    "print(split_docs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba50687c-7828-40e5-b544-497224aa51ee",
   "metadata": {},
   "source": [
    "#### Generate vector embeddings for the chunks and store them in MongoDB using a OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b9f21c50-44bd-4139-9d05-3a8f81dd927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import MongoDBAtlasVectorSearch, ChatOpenAI and OpenAIEmbeddings\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "13cfea73-62bf-48df-9aff-896e24b94ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating vector embeddings for the documents\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a variable called `embeddings` that is an instance of OpenAIEmbeddings with the `openai_api_key` set to `my_openai_key`\n",
    "print(\"Generating vector embeddings for the documents\")\n",
    "embeddings = OpenAIEmbeddings(openai_api_key=my_openai_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ecaaf472-7517-4452-9f91-562435ba8e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the MongoDB client for storing the chunked data\n",
    "from pymongo import MongoClient\n",
    "client = MongoClient(mongodb_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "788ec84c-4dd0-48e3-a397-9759a4404303",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = client[db_name][collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b7001f99-e1fb-4745-a754-47d7f9ed13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the collection before adding new data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 0, 'electionId': ObjectId('7fffffff0000000000000105'), 'opTime': {'ts': Timestamp(1729745564, 6), 't': 261}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1729745564, 6), 'signature': {'hash': b'^\\x1f10~0\\xdf\\xc6\\x06A\\xfc\\xaf\\xf5<]\\xf9&\\x83AW', 'keyId': 7374128216354586628}}, 'operationTime': Timestamp(1729745564, 6)}, acknowledged=True)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the database before adding new data\n",
    "print(\"Deleting the collection before adding new data\")\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1957a370-1bae-4b0d-a60b-40a52b175987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing the vectors in MongoDB Atlas\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create a variable called `vector_store`. \n",
    "# Set it to an instance of MongoDBAtlasVectorSearch.from_documents and pass in the `split_docs`, `embeddings`, and `collection`\n",
    "print(\"Storing the vectors in MongoDB Atlas\")\n",
    "vector_store = MongoDBAtlasVectorSearch.from_documents(split_docs, embeddings, collection=collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a6eb5040-ccd3-4852-b772-6f5410c15e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully stored 173 documents in MongoDB Atlas\n"
     ]
    }
   ],
   "source": [
    "document_count = collection.count_documents({})\n",
    "print(f\"Successfully stored {document_count} documents in MongoDB Atlas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79664dc-4016-4ea1-8a41-e0b35a809ecb",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "eec81463-7bab-4c63-8a3a-6f4a9209ed12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42415ed6-3682-44d0-ae75-ae3eb9da530c",
   "metadata": {},
   "source": [
    "#### Create the following vector search index on the chunked_data collection in your Atlas Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8af30adc-82f0-4992-a550-aca4ccb4649f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#   \"fields\": [\n",
    "#     {\n",
    "#       \"numDimensions\": 1536,\n",
    "#       \"path\": \"embedding\",\n",
    "#       \"similarity\": \"cosine\",\n",
    "#       \"type\": \"vector\"\n",
    "#     },\n",
    "#     {\n",
    "#       \"path\": \"hasCode\",\n",
    "#       \"type\": \"filter\"\n",
    "#     }\n",
    "#   ]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "6839fa4c-6965-4e58-a46f-d79c4dbeb56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create the vector store\n",
    "vector_store = MongoDBAtlasVectorSearch.from_connection_string(\n",
    "    connection_string=mongodb_uri,\n",
    "    namespace=f\"{db_name}.{collection_name}\",\n",
    "    embedding=OpenAIEmbeddings(disallowed_special=(),\n",
    "        openai_api_key=my_openai_key),\n",
    "    index_name=index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "3aabac02-e9bd-4d7b-808b-94417e837627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the query_data function\n",
    "def query_data(query):\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3},\n",
    "    )\n",
    "    results = retriever.invoke(query)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "a0953f6e-8c5b-4dfc-a18a-bdf0d72f02c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a prefilter to the retriever by updating the query_data\n",
    "def query_data(query):\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\n",
    "            \"k\": 3,\n",
    "            \"pre_filter\": { \"hasCode\": { \"$eq\": False } },\n",
    "            \"score_threshold\": 0.01\n",
    "        },\n",
    "    )\n",
    "\n",
    "    results = retriever.invoke(query)\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "e4049ce6-5ec2-4e6f-abce-054bd94339c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'_id': '6719d2c776b49b966151d21f', 'title': 'MongoDB Overview', 'keywords': ['MongoDB', 'relational database', 'transactions', 'data storage'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 34}, page_content='restrictions on application developers. The addition of transactions addressed a legiti-\\nmate and serious concern. So, when people ask where does MongoDB sit with respect\\nto the new data storage landscape? the answer is simple: right in the middle .\\n34'), Document(metadata={'_id': '6719d2c776b49b966151d210', 'title': 'MongoDB Features', 'keywords': ['capped collections', 'TTL Indexes', 'Durability', 'journaling', 'full text search', 'ACID transactions'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 31}, page_content='engine. With MongoDB’s support for arrays and full text search, you will only need to\\nlook to other solutions if you need a more powerful and full-featured full text search\\nengine.\\nTransactions\\nMongoDB added full support for ACID transactions26in 4.0 (extending it to sharded\\nclusters in 4.2). Before that there were two alternatives, one which is great and still has\\nits place, and the other that was cumbersome but flexible.'), Document(metadata={'_id': '6719d2c776b49b966151d213', 'title': 'MongoDB Features', 'keywords': ['findAndModify', 'atomicity', 'two-phase commit', 'transactions', 'geospatial indexes', 'replication'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 32}, page_content='It’s a storage-agnostic solution that you do in code. Two-phase commits are actu-\\nally quite popular in the relational world as a way to implement transactions across\\nmultiple databases. The general idea is that you store the state of the transaction\\nwithin the actual document being updated atomically and go through the init-pending-\\ncommit/rollback steps manually. This is the case where using MongoDB multi-document')]\n"
     ]
    }
   ],
   "source": [
    "# Query the data\n",
    "query_data(\"When did MongoDB begin supporting multi-document transactions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f72429d8-d99d-4f39-ae3a-a004e2371717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'_id': '6719d2c776b49b966151d18a', 'title': 'Chapter 1 - The Basics', 'keywords': ['MongoDB', 'database', 'collection', 'document', 'field', 'index', 'cursor'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 5}, page_content='familiar (or a schema for you Oracle folks). Within a MongoDB instance you can\\nhave zero or more databases, each acting as high-level containers for everything\\nelse.\\n2.A database can have zero or more collections . A collection shares enough in\\ncommon with a traditional table that you can safely think of the two as the same\\nthing.\\n3.Collections are made up of zero or more documents . Again, a document can safely\\nbe thought of as analogous to a row.'), Document(metadata={'_id': '6719d2c776b49b966151d18b', 'title': 'Chapter 1 - The Basics', 'keywords': ['MongoDB', 'database', 'collection', 'document', 'field', 'index', 'cursor'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 5}, page_content='thing.\\n3.Collections are made up of zero or more documents . Again, a document can safely\\nbe thought of as analogous to a row.\\n4.A document is made up of one or more fields , which you can probably guess\\nare somewhat like columns .\\n5.Indexes in MongoDB function mostly like their RDBMS counterparts.\\n6.Cursors are like relational database cursors, but they are important enough, and\\noften overlooked, that I think they are worthy of their own discussion. The impor-'), Document(metadata={'_id': '6719d2c776b49b966151d183', 'title': 'Getting Started', 'keywords': ['MongoDB', 'drivers', 'Mongoose', 'Spring Data MongoDB', 'MongoDB Shell', 'MongoDB Compass', 'MongoDB Atlas'], 'hasCode': False, 'source': './mongodb.pdf', 'page': 3}, page_content='collection in Java. Whether you choose to program directly against the core MongoDB\\ndrivers or some higher-level library is up to you. I point this out only because many peo-\\nple new to MongoDB are confused as to why there are both official drivers and commu-\\nnity libraries - the former generally focuses on core communication/connectivity with\\nMongoDB and the latter with more language and framework-specific implementations.')]\n"
     ]
    }
   ],
   "source": [
    "query_data(\"What is the difference between a database and collection in MongoDB?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e35d154-3886-4b24-ad88-07d738d1799c",
   "metadata": {},
   "source": [
    "# Answer Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a481fb16-9791-435b-91cc-cec7628f4538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the answer generation component of your RAG application. \n",
    "# This involves updating the query_data function to generate answers based on specific prompts \n",
    "# using a custom template and a series of steps in LangChain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "8f8bd41b-8c3d-4ea3-a202-3c2dd944b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.output_parsers import StrOutputParser # New import\n",
    "from langchain_core.runnables import RunnablePassthrough # New import\n",
    "from langchain.prompts import PromptTemplate # New import\n",
    "from langchain_mongodb import MongoDBAtlasVectorSearch\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "552ace11-9f13-45b6-8ae3-3cfbf8a86de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_data(query):\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3},\n",
    "    )\n",
    "\n",
    "    # TODO: Define the template string\n",
    "    template = \"\"\"\n",
    "    Use the following pieces of context to answer the question at the end.\n",
    "    If you don't know the answer, just say that you don't know, don't try to make up an answer.\n",
    "    Do not answer the question if there is no given context.\n",
    "    Do not answer the question if it is not related to the context.\n",
    "    Do not give recommendations to anything other than MongoDB.\n",
    "    Context:\n",
    "    {context}\n",
    "    Question: {question}\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Instatiate a custom PromptTemplate object\n",
    "    # Instantiate the PromptTemplate using PromptTemplate.from_template()\n",
    "    # and assign the result to custom_rag_prompt, passing the template as an argument.\n",
    "    custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "    # TODO: Add context and question to the retrieve dictionary\n",
    "    # Update the dictionary called retrieve and provide values for context and question. \n",
    "    # Use the retriever object for the context and RunnablePassthrough() for the question.\n",
    "    retrieve = {\n",
    "        \"context\": retriever\n",
    "        | (lambda docs: \"\\n\\n\".join([d.page_content for d in docs])),\n",
    "        \"question\": RunnablePassthrough(), \n",
    "    }\n",
    "\n",
    "    llm = ChatOpenAI(openai_api_key=my_openai_key, temperature=0)\n",
    "\n",
    "    # TODO: Instatiate a custom StrOutputParser object\n",
    "    response_parser = StrOutputParser()\n",
    "\n",
    "    # TODO: Create a RAG chain with the retrieve, custom_rag_prompt, llm, and response_parser objects (separated by | )\n",
    "    rag_chain = retrieve | custom_rag_prompt | llm | response_parser\n",
    "    answer = rag_chain.invoke(query)\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "0e514c25-8062-4b2f-b3b8-22a7ec334f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query: When did MongoDB begin supporting multi-document transactions?\n",
      "MongoDB began supporting multi-document transactions in version 4.0.\n"
     ]
    }
   ],
   "source": [
    "# Test with a relevant query\n",
    "question = \"When did MongoDB begin supporting multi-document transactions?\"\n",
    "print(f\"Running query: {question}\")\n",
    "query_data(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f6417488-09e8-48a5-83dd-877e869b1df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query: Why is the sky blue?\n",
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "# Test with an irrelevant query\n",
    "question = \"Why is the sky blue?\"\n",
    "print(f\"Running query: {question}\")\n",
    "query_data(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8acdcdbf-1342-45f6-a161-f7128ff77398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query: What is the difference between a database and collection in MongoDB?\n",
      "In MongoDB, a database can have zero or more collections. A collection is similar to a traditional table in a relational database, while a database acts as a high-level container for collections. So, the main difference is that a database contains collections, which in turn contain documents.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is the difference between a database and collection in MongoDB?\"\n",
    "print(f\"Running query: {question}\")\n",
    "query_data(question)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
